{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b80ee23",
   "metadata": {
    "papermill": {
     "duration": 0.005963,
     "end_time": "2023-12-07T03:32:40.573108",
     "exception": false,
     "start_time": "2023-12-07T03:32:40.567145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**NOTE: This submission utilizes the maximum inference time limit, so depending on the situation, a submission scoring error may occur. \n",
    "\n",
    "However, you can succeed by trying multiple times.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcef8201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:40.584819Z",
     "iopub.status.busy": "2023-12-07T03:32:40.584020Z",
     "iopub.status.idle": "2023-12-07T03:32:47.911143Z",
     "shell.execute_reply": "2023-12-07T03:32:47.910030Z"
    },
    "papermill": {
     "duration": 7.33632,
     "end_time": "2023-12-07T03:32:47.914326",
     "exception": false,
     "start_time": "2023-12-07T03:32:40.578006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"Read a JSON file and parse it into a Python object.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file to read.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary object representing the JSON data.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified file path does not exist.\n",
    "        ValueError: If the specified file path does not contain valid JSON data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the file and load the JSON data into a Python object\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        return json_data\n",
    "    except FileNotFoundError:\n",
    "        # Raise an error if the file path does not exist\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    except ValueError:\n",
    "        # Raise an error if the file does not contain valid JSON data\n",
    "        raise ValueError(f\"Invalid JSON data in file: {file_path}\")\n",
    "\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaefd816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:47.926514Z",
     "iopub.status.busy": "2023-12-07T03:32:47.925757Z",
     "iopub.status.idle": "2023-12-07T03:32:48.196141Z",
     "shell.execute_reply": "2023-12-07T03:32:48.194828Z"
    },
    "papermill": {
     "duration": 0.279307,
     "end_time": "2023-12-07T03:32:48.198765",
     "exception": false,
     "start_time": "2023-12-07T03:32:47.919458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "... LOAD SIGN TO PREDICTION INDEX MAP FROM JSON FILE ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/asl-signs/train.csv')\n",
    "print(\"\\n\\n... LOAD SIGN TO PREDICTION INDEX MAP FROM JSON FILE ...\\n\")\n",
    "s2p_map = {k.lower():v for k,v in read_json_file(os.path.join(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\")).items()}\n",
    "p2s_map = {v:k for k,v in read_json_file(os.path.join(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\")).items()}\n",
    "encoder = lambda x: s2p_map.get(x.lower())\n",
    "decoder = lambda x: p2s_map.get(x)\n",
    "# print(s2p_map)\n",
    "train_df['label'] = train_df.sign.map(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f018b882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:48.210564Z",
     "iopub.status.busy": "2023-12-07T03:32:48.209767Z",
     "iopub.status.idle": "2023-12-07T03:32:48.241486Z",
     "shell.execute_reply": "2023-12-07T03:32:48.240256Z"
    },
    "papermill": {
     "duration": 0.039805,
     "end_time": "2023-12-07T03:32:48.243712",
     "exception": false,
     "start_time": "2023-12-07T03:32:48.203907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "708\n"
     ]
    }
   ],
   "source": [
    "ROWS_PER_FRAME = 543\n",
    "MAX_LEN = 384\n",
    "CROP_LEN = MAX_LEN\n",
    "NUM_CLASSES  = 250\n",
    "PAD = -100.\n",
    "NOSE=[\n",
    "    1,2,98,327\n",
    "]\n",
    "LNOSE = [98]\n",
    "RNOSE = [327]\n",
    "LIP = [ 0, \n",
    "    61, 185, 40, 39, 37, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "LLIP = [84,181,91,146,61,185,40,39,37,87,178,88,95,78,191,80,81,82]\n",
    "RLIP = [314,405,321,375,291,409,270,269,267,317,402,318,324,308,415,310,311,312]\n",
    "\n",
    "POSE = [500, 502, 504, 501, 503, 505, 512, 513]\n",
    "LPOSE = [513,505,503,501]\n",
    "RPOSE = [512,504,502,500]\n",
    "\n",
    "REYE = [\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    246, 161, 160, 159, 158, 157, 173,\n",
    "]\n",
    "LEYE = [\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362,\n",
    "    466, 388, 387, 386, 385, 384, 398,\n",
    "]\n",
    "\n",
    "LHAND = np.arange(468, 489).tolist()\n",
    "RHAND = np.arange(522, 543).tolist()\n",
    "\n",
    "POINT_LANDMARKS = LIP + LHAND + RHAND + NOSE + REYE + LEYE #+POSE\n",
    "\n",
    "NUM_NODES = len(POINT_LANDMARKS)\n",
    "CHANNELS = 6*NUM_NODES\n",
    "\n",
    "print(NUM_NODES)\n",
    "print(CHANNELS)\n",
    "\n",
    "def tf_nan_mean(x, axis=0, keepdims=False):\n",
    "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis, keepdims=keepdims) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis, keepdims=keepdims)\n",
    "\n",
    "def tf_nan_std(x, center=None, axis=0, keepdims=False):\n",
    "    if center is None:\n",
    "        center = tf_nan_mean(x, axis=axis,  keepdims=True)\n",
    "    d = x - center\n",
    "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis, keepdims=keepdims))\n",
    "\n",
    "class Preprocess(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len=MAX_LEN, point_landmarks=POINT_LANDMARKS, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.max_len = max_len\n",
    "        self.point_landmarks = point_landmarks\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if tf.rank(inputs) == 3:\n",
    "            x = inputs[None,...]\n",
    "        else:\n",
    "            x = inputs\n",
    "        \n",
    "        mean = tf_nan_mean(tf.gather(x, [17], axis=2), axis=[1,2], keepdims=True)\n",
    "        mean = tf.where(tf.math.is_nan(mean), tf.constant(0.5,x.dtype), mean)\n",
    "        x = tf.gather(x, self.point_landmarks, axis=2) #N,T,P,C\n",
    "        std = tf_nan_std(x, center=mean, axis=[1,2], keepdims=True)\n",
    "        \n",
    "        x = (x - mean)/std\n",
    "\n",
    "        if self.max_len is not None:\n",
    "            x = x[:,:self.max_len]\n",
    "        length = tf.shape(x)[1]\n",
    "        x = x[...,:2]\n",
    "\n",
    "        dx = tf.cond(tf.shape(x)[1]>1,lambda:tf.pad(x[:,1:] - x[:,:-1], [[0,0],[0,1],[0,0],[0,0]]),lambda:tf.zeros_like(x))\n",
    "\n",
    "        dx2 = tf.cond(tf.shape(x)[1]>2,lambda:tf.pad(x[:,2:] - x[:,:-2], [[0,0],[0,2],[0,0],[0,0]]),lambda:tf.zeros_like(x))\n",
    "\n",
    "        x = tf.concat([\n",
    "            tf.reshape(x, (-1,length,2*len(self.point_landmarks))),\n",
    "            tf.reshape(dx, (-1,length,2*len(self.point_landmarks))),\n",
    "            tf.reshape(dx2, (-1,length,2*len(self.point_landmarks))),\n",
    "        ], axis = -1)\n",
    "        \n",
    "        x = tf.where(tf.math.is_nan(x),tf.constant(0.,x.dtype),x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee2420a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:48.255455Z",
     "iopub.status.busy": "2023-12-07T03:32:48.255113Z",
     "iopub.status.idle": "2023-12-07T03:32:48.281363Z",
     "shell.execute_reply": "2023-12-07T03:32:48.280326Z"
    },
    "papermill": {
     "duration": 0.035687,
     "end_time": "2023-12-07T03:32:48.284402",
     "exception": false,
     "start_time": "2023-12-07T03:32:48.248715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ECA(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n",
    "        nn = tf.expand_dims(nn, -1)\n",
    "        nn = self.conv(nn)\n",
    "        nn = tf.squeeze(nn, -1)\n",
    "        nn = tf.nn.sigmoid(nn)\n",
    "        nn = nn[:,None,:]\n",
    "        return inputs * nn\n",
    "\n",
    "class LateDropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, rate, noise_shape=None, start_step=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.rate = rate\n",
    "        self.start_step = start_step\n",
    "        self.dropout = tf.keras.layers.Dropout(rate, noise_shape=noise_shape)\n",
    "      \n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n",
    "        self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg, trainable=False)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = tf.cond(self._train_counter < self.start_step, lambda:inputs, lambda:self.dropout(inputs, training=training))\n",
    "        if training:\n",
    "            self._train_counter.assign_add(1)\n",
    "        return x\n",
    "\n",
    "class CausalDWConv1D(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "        kernel_size=17,\n",
    "        dilation_rate=1,\n",
    "        use_bias=False,\n",
    "        depthwise_initializer='glorot_uniform',\n",
    "        name='', **kwargs):\n",
    "        super().__init__(name=name,**kwargs)\n",
    "        self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n",
    "        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n",
    "                            kernel_size,\n",
    "                            strides=1,\n",
    "                            dilation_rate=dilation_rate,\n",
    "                            padding='valid',\n",
    "                            use_bias=use_bias,\n",
    "                            depthwise_initializer=depthwise_initializer,\n",
    "                            name=name + '_dwconv')\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.causal_pad(inputs)\n",
    "        x = self.dw_conv(x)\n",
    "        return x\n",
    "\n",
    "def Conv1DBlock(channel_size,\n",
    "          kernel_size,\n",
    "          dilation_rate=1,\n",
    "          drop_rate=0.0,\n",
    "          expand_ratio=2,\n",
    "          se_ratio=0.25,\n",
    "          activation='swish',\n",
    "          name=None):\n",
    "    '''\n",
    "    efficient conv1d block, @hoyso48\n",
    "    '''\n",
    "    if name is None:\n",
    "        name = str(tf.keras.backend.get_uid(\"mbblock\"))\n",
    "    # Expansion phase\n",
    "    def apply(inputs):\n",
    "        channels_in = tf.keras.backend.int_shape(inputs)[-1]\n",
    "        channels_expand = channels_in * expand_ratio\n",
    "\n",
    "        skip = inputs\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channels_expand,\n",
    "            use_bias=True,\n",
    "            activation=activation,\n",
    "            name=name + '_expand_conv')(inputs)\n",
    "\n",
    "        # Depthwise Convolution\n",
    "        x = CausalDWConv1D(kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            use_bias=False,\n",
    "            name=name + '_dwconv')(x)\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95, name=name + '_bn')(x)\n",
    "\n",
    "        x  = ECA()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channel_size,\n",
    "            use_bias=True,\n",
    "            name=name + '_project_conv')(x)\n",
    "\n",
    "        if drop_rate > 0:\n",
    "            x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1), name=name + '_drop')(x)\n",
    "\n",
    "        if (channels_in == channel_size):\n",
    "            x = tf.keras.layers.add([x, skip], name=name + '_add')\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6156a9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:48.296906Z",
     "iopub.status.busy": "2023-12-07T03:32:48.296351Z",
     "iopub.status.idle": "2023-12-07T03:32:48.314670Z",
     "shell.execute_reply": "2023-12-07T03:32:48.313684Z"
    },
    "papermill": {
     "duration": 0.026725,
     "end_time": "2023-12-07T03:32:48.316826",
     "exception": false,
     "start_time": "2023-12-07T03:32:48.290101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim=256, num_heads=4, dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.scale = self.dim ** -0.5\n",
    "        self.num_heads = num_heads\n",
    "        self.qkv = tf.keras.layers.Dense(3 * dim, use_bias=False)\n",
    "        self.drop1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.proj = tf.keras.layers.Dense(dim, use_bias=False)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        qkv = self.qkv(inputs)\n",
    "        qkv = tf.keras.layers.Permute((2, 1, 3))(tf.keras.layers.Reshape((-1, self.num_heads, self.dim * 3 // self.num_heads))(qkv))\n",
    "        q, k, v = tf.split(qkv, [self.dim // self.num_heads] * 3, axis=-1)\n",
    "\n",
    "        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask[:, None, None, :]\n",
    "\n",
    "        attn = tf.keras.layers.Softmax(axis=-1)(attn, mask=mask)\n",
    "        attn = self.drop1(attn)\n",
    "\n",
    "        x = attn @ v\n",
    "        x = tf.keras.layers.Reshape((-1, self.dim))(tf.keras.layers.Permute((2, 1, 3))(x))\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def TransformerBlock(dim=256, num_heads=4, expand=4, attn_dropout=0.2, drop_rate=0.2, activation='swish'):\n",
    "    def apply(inputs):\n",
    "        x = inputs\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n",
    "        x = MultiHeadSelfAttention(dim=dim,num_heads=num_heads,dropout=attn_dropout)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([inputs, x])\n",
    "        attn_out = x\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n",
    "        x = tf.keras.layers.Dense(dim*expand, use_bias=False, activation=activation)(x)\n",
    "        x = tf.keras.layers.Dense(dim, use_bias=False)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([attn_out, x])\n",
    "        return x\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eabc435e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:48.329180Z",
     "iopub.status.busy": "2023-12-07T03:32:48.328219Z",
     "iopub.status.idle": "2023-12-07T03:32:48.343621Z",
     "shell.execute_reply": "2023-12-07T03:32:48.342549Z"
    },
    "papermill": {
     "duration": 0.02396,
     "end_time": "2023-12-07T03:32:48.345912",
     "exception": false,
     "start_time": "2023-12-07T03:32:48.321952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(max_len=MAX_LEN, dropout_step=0, dim=192):\n",
    "    inp = tf.keras.Input((max_len,CHANNELS))\n",
    "    #x = tf.keras.layers.Masking(mask_value=PAD,input_shape=(max_len,CHANNELS))(inp) #we don't need masking layer with inference\n",
    "    x = inp\n",
    "    ksize = 17\n",
    "    x = tf.keras.layers.Dense(dim, use_bias=False,name='stem_conv')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(momentum=0.95,name='stem_bn')(x)\n",
    "\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    if dim == 384: #for the 4x sized model\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(dim*2,activation=None,name='top_conv')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = LateDropout(0.8, start_step=dropout_step)(x)\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES,name='classifier')(x)\n",
    "    return tf.keras.Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8873e510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:48.357600Z",
     "iopub.status.busy": "2023-12-07T03:32:48.357082Z",
     "iopub.status.idle": "2023-12-07T03:32:52.854081Z",
     "shell.execute_reply": "2023-12-07T03:32:52.853040Z"
    },
    "papermill": {
     "duration": 4.537334,
     "end_time": "2023-12-07T03:32:52.888477",
     "exception": false,
     "start_time": "2023-12-07T03:32:48.351143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 384, 708)]   0           []                               \n",
      "                                                                                                  \n",
      " stem_conv (Dense)              (None, 384, 192)     135936      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 384, 192)     768         ['stem_conv[0][0]']              \n",
      "                                                                                                  \n",
      " 1_expand_conv (Dense)          (None, 384, 384)     74112       ['stem_bn[0][0]']                \n",
      "                                                                                                  \n",
      " 1_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['1_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 1_bn (BatchNormalization)      (None, 384, 384)     1536        ['1_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca (ECA)                      (None, 384, 384)     5           ['1_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 1_project_conv (Dense)         (None, 384, 192)     73920       ['eca[0][0]']                    \n",
      "                                                                                                  \n",
      " 1_drop (Dropout)               (None, 384, 192)     0           ['1_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 1_add (Add)                    (None, 384, 192)     0           ['1_drop[0][0]',                 \n",
      "                                                                  'stem_bn[0][0]']                \n",
      "                                                                                                  \n",
      " 2_expand_conv (Dense)          (None, 384, 384)     74112       ['1_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 2_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['2_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 2_bn (BatchNormalization)      (None, 384, 384)     1536        ['2_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_1 (ECA)                    (None, 384, 384)     5           ['2_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 2_project_conv (Dense)         (None, 384, 192)     73920       ['eca_1[0][0]']                  \n",
      "                                                                                                  \n",
      " 2_drop (Dropout)               (None, 384, 192)     0           ['2_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 2_add (Add)                    (None, 384, 192)     0           ['2_drop[0][0]',                 \n",
      "                                                                  '1_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 3_expand_conv (Dense)          (None, 384, 384)     74112       ['2_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 3_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['3_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 3_bn (BatchNormalization)      (None, 384, 384)     1536        ['3_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_2 (ECA)                    (None, 384, 384)     5           ['3_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 3_project_conv (Dense)         (None, 384, 192)     73920       ['eca_2[0][0]']                  \n",
      "                                                                                                  \n",
      " 3_drop (Dropout)               (None, 384, 192)     0           ['3_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 3_add (Add)                    (None, 384, 192)     0           ['3_drop[0][0]',                 \n",
      "                                                                  '2_add[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 384, 192)    768         ['3_add[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_self_attention (Mul  (None, 384, 192)    147456      ['batch_normalization[0][0]']    \n",
      " tiHeadSelfAttention)                                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 384, 192)     0           ['multi_head_self_attention[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 384, 192)     0           ['3_add[0][0]',                  \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 384, 192)    768         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 384, 384)     73728       ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 384, 192)     73728       ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 384, 192)     0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 384, 192)     0           ['add[0][0]',                    \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " 4_expand_conv (Dense)          (None, 384, 384)     74112       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " 4_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['4_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 4_bn (BatchNormalization)      (None, 384, 384)     1536        ['4_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_3 (ECA)                    (None, 384, 384)     5           ['4_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 4_project_conv (Dense)         (None, 384, 192)     73920       ['eca_3[0][0]']                  \n",
      "                                                                                                  \n",
      " 4_drop (Dropout)               (None, 384, 192)     0           ['4_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 4_add (Add)                    (None, 384, 192)     0           ['4_drop[0][0]',                 \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " 5_expand_conv (Dense)          (None, 384, 384)     74112       ['4_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 5_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['5_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 5_bn (BatchNormalization)      (None, 384, 384)     1536        ['5_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_4 (ECA)                    (None, 384, 384)     5           ['5_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 5_project_conv (Dense)         (None, 384, 192)     73920       ['eca_4[0][0]']                  \n",
      "                                                                                                  \n",
      " 5_drop (Dropout)               (None, 384, 192)     0           ['5_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 5_add (Add)                    (None, 384, 192)     0           ['5_drop[0][0]',                 \n",
      "                                                                  '4_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 6_expand_conv (Dense)          (None, 384, 384)     74112       ['5_add[0][0]']                  \n",
      "                                                                                                  \n",
      " 6_dwconv (CausalDWConv1D)      (None, 384, 384)     6528        ['6_expand_conv[0][0]']          \n",
      "                                                                                                  \n",
      " 6_bn (BatchNormalization)      (None, 384, 384)     1536        ['6_dwconv[0][0]']               \n",
      "                                                                                                  \n",
      " eca_5 (ECA)                    (None, 384, 384)     5           ['6_bn[0][0]']                   \n",
      "                                                                                                  \n",
      " 6_project_conv (Dense)         (None, 384, 192)     73920       ['eca_5[0][0]']                  \n",
      "                                                                                                  \n",
      " 6_drop (Dropout)               (None, 384, 192)     0           ['6_project_conv[0][0]']         \n",
      "                                                                                                  \n",
      " 6_add (Add)                    (None, 384, 192)     0           ['6_drop[0][0]',                 \n",
      "                                                                  '5_add[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 384, 192)    768         ['6_add[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_self_attention_1 (M  (None, 384, 192)    147456      ['batch_normalization_2[0][0]']  \n",
      " ultiHeadSelfAttention)                                                                           \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 384, 192)     0           ['multi_head_self_attention_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 384, 192)     0           ['6_add[0][0]',                  \n",
      "                                                                  'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 384, 192)    768         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 384, 384)     73728       ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 384, 192)     73728       ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 384, 192)     0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 384, 192)     0           ['add_2[0][0]',                  \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " top_conv (Dense)               (None, 384, 384)     74112       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 384)         0           ['top_conv[0][0]']               \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " late_dropout (LateDropout)     (None, 384)          1           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 250)          96250       ['late_dropout[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,836,569\n",
      "Trainable params: 1,830,040\n",
      "Non-trainable params: 6,529\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models_path = [\n",
    "              '/kaggle/input/modelcv/islr-fp16-192-8-seed42-fold0-best.h5', #comment out other weights to check single model score\n",
    "               #'/kaggle/input/islr-models/islr-fp16-192-8-seed43-foldall-last.h5',\n",
    "               #'/kaggle/input/islr-models/islr-fp16-192-8-seed44-foldall-last.h5',\n",
    "               #'/kaggle/input/islr-models/islr-fp16-192-8-seed45-foldall-last.h5',\n",
    "              ]\n",
    "models = [get_model() for _ in models_path]\n",
    "for model,path in zip(models,models_path):\n",
    "    model.load_weights(path)\n",
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a0556ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:52.925312Z",
     "iopub.status.busy": "2023-12-07T03:32:52.924920Z",
     "iopub.status.idle": "2023-12-07T03:32:52.934801Z",
     "shell.execute_reply": "2023-12-07T03:32:52.933799Z"
    },
    "papermill": {
     "duration": 0.030858,
     "end_time": "2023-12-07T03:32:52.936868",
     "exception": false,
     "start_time": "2023-12-07T03:32:52.906010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TFLiteModel(tf.Module):\n",
    "    \"\"\"\n",
    "    TensorFlow Lite model that takes input tensors and applies:\n",
    "        – a preprocessing model\n",
    "        – the ISLR model \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, islr_models):\n",
    "        \"\"\"\n",
    "        Initializes the TFLiteModel with the specified preprocessing model and ISLR model.\n",
    "        \"\"\"\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.prep_inputs = Preprocess()\n",
    "        self.islr_models   = islr_models\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"\n",
    "        Applies the feature generation model and main model to the input tensors.\n",
    "\n",
    "        Args:\n",
    "            inputs: Input tensor with shape [batch_size, 543, 3].\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with a single key 'outputs' and corresponding output tensor.\n",
    "        \"\"\"\n",
    "        x = self.prep_inputs(tf.cast(inputs, dtype=tf.float32))\n",
    "        outputs = [model(x) for model in self.islr_models]\n",
    "        outputs = tf.keras.layers.Average()(outputs)[0]\n",
    "        return {'outputs': outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5662f313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:52.972041Z",
     "iopub.status.busy": "2023-12-07T03:32:52.971705Z",
     "iopub.status.idle": "2023-12-07T03:32:52.977918Z",
     "shell.execute_reply": "2023-12-07T03:32:52.976795Z"
    },
    "papermill": {
     "duration": 0.02611,
     "end_time": "2023-12-07T03:32:52.980023",
     "exception": false,
     "start_time": "2023-12-07T03:32:52.953913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet('/kaggle/input/asl-signs/' + pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f4cb116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T03:32:53.015407Z",
     "iopub.status.busy": "2023-12-07T03:32:53.014708Z",
     "iopub.status.idle": "2023-12-07T03:32:59.515109Z",
     "shell.execute_reply": "2023-12-07T03:32:59.513856Z"
    },
    "papermill": {
     "duration": 6.520571,
     "end_time": "2023-12-07T03:32:59.517450",
     "exception": false,
     "start_time": "2023-12-07T03:32:52.996879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blow'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_keras_model = TFLiteModel(islr_models=models)\n",
    "demo_output = tflite_keras_model(load_relevant_data_subset(train_df.path[0]))[\"outputs\"]\n",
    "decoder(np.argmax(demo_output.numpy(), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37190086",
   "metadata": {
    "papermill": {
     "duration": 0.016827,
     "end_time": "2023-12-07T03:32:59.552007",
     "exception": false,
     "start_time": "2023-12-07T03:32:59.535180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1a723",
   "metadata": {
    "papermill": {
     "duration": 0.01934,
     "end_time": "2023-12-07T03:32:59.590031",
     "exception": false,
     "start_time": "2023-12-07T03:32:59.570691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 5087314,
     "sourceId": 46105,
     "sourceType": "competition"
    },
    {
     "datasetId": 3221731,
     "sourceId": 5600436,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4120147,
     "sourceId": 7139137,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30408,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.95045,
   "end_time": "2023-12-07T03:33:03.096120",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-07T03:32:30.145670",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
